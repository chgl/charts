# -- metadata.annotations to apply to the deployment
deploymentAnnotations: {}

# -- String to partially override fullname template (will maintain the release name)
nameOverride: ""

# -- String to fully override fullname template
fullnameOverride: ""

# -- image pull secrets
imagePullSecrets: []

# @ignored
image:
  registry: docker.io
  repository: aehrc/pathling
  tag: 6.4.2@sha256:9b8ee32d4b8bb40192d6bf25814492a616153a0df15d178c286db9ec80c1c85e
  pullPolicy: IfNotPresent

# -- number of replicas. This components can also be easily scaled horizontally if necessary.
replicaCount: 1

# -- pod annotations
podAnnotations: {}

# -- the pod security context
podSecurityContext:
  {}
  # fsGroup: 2000

# -- the container security context
# @ignored
securityContext:
  allowPrivilegeEscalation: false
  privileged: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 99
  runAsGroup: 99
  seccompProfile:
    type: RuntimeDefault

# -- service used to expose the API
service:
  # -- type of service
  type: ClusterIP
  # -- service port
  port: 8080
  spark:
    ui:
      # -- service port for the Spark UI
      port: 4040
    driver:
      # -- service port for the Spark driver
      port: 7077
    blockManager:
      # -- service port for the Spark block manager
      port: 7078
  metrics:
    port: 8081

metrics:
  serviceMonitor:
    # if enabled, creates a ServiceMonitor instance for Prometheus Operator-based monitoring
    enabled: false
    # additional labels for the ServiceMonitor resource, e.g. `release: prometheus`
    additionalLabels: {}
    # namespace: monitoring
    # interval: 30s
    # scrapeTimeout: 10s

# resource requests and limits
resources:
  {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# -- extra environment variables to apply to the container
extraEnv: []
# - name: pathling.spark.appName
#   value: "aDifferentName"

ingress:
  # create an Ingress for the application
  enabled: false
  # ingressClassName to use
  className: ""
  # extra annotations to apply to the Ingress resource
  annotations:
    {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  # list of ingress hosts
  hosts:
    - host: pathling-server.127.0.0.1.nip.io
      paths:
        - path: /
          pathType: ImplementationSpecific
          portName: http
  # TLS configuration
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# -- node labels for pods assignment
# see: <https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/>
nodeSelector: {}

# -- tolerations for pods assignment
# see: <https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/>
tolerations: []

# -- affinity for pods assignment
# see: <https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity>
affinity: {}

# @ignored
readinessProbe:
  enabled: true
  httpGet:
    path: /readyz
    port: http
  failureThreshold: 5
  initialDelaySeconds: 30
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 5

# @ignored
livenessProbe:
  enabled: true
  httpGet:
    path: /livez
    port: http
  failureThreshold: 10
  initialDelaySeconds: 30
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 10

# @ignored
startupProbe:
  enabled: true
  httpGet:
    path: /livez
    port: http
  failureThreshold: 10
  initialDelaySeconds: 30
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 10

# -- pod topology spread configuration
# see: <https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#api>
topologySpreadConstraints:
  []
  # - maxSkew: 1
  #   topologyKey: topology.kubernetes.io/zone
  #   whenUnsatisfiable: ScheduleAnyway
  #   labelSelector:
  #     matchLabels:
  #       app.kubernetes.io/name: pathling-server
  #       app.kubernetes.io/instance: pathling-server

podDisruptionBudget:
  # -- create a PodDisruptionBudget resource
  enabled: false
  # -- Minimum available instances; ignored if there is no PodDisruptionBudget
  minAvailable: 1
  # -- Maximum unavailable instances; ignored if there is no PodDisruptionBudget
  maxUnavailable: ""

autoscaling:
  # -- enable horizontal pod autoscaling
  enabled: false
  # -- minReplicas is the lower limit for the number of replicas to which the autoscaler can scale down.
  # It defaults to 1 pod. minReplicas is allowed to be 0 if the alpha feature gate HPAScaleToZero is
  # enabled and at least one Object or External metric is configured.
  # Scaling is active as long as at least one metric value is available.
  minReplicas: 1
  # -- upper limit for the number of pods that can be set by the autoscaler; cannot be smaller than `minReplicas`.
  maxReplicas: 5
  # -- target average CPU utilization (represented as a percentage of requested CPU)
  # over all the pods; if not specified the default autoscaling policy will be used.
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

serviceAccount:
  # -- Specifies whether a service account should be created. Used to setup Spark executor pods if `spark.cluster.enabled=true`.
  create: true
  # -- Annotations to add to the service account
  annotations: {}
  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""
  # -- whether to automount the SA token
  automountServiceAccountToken: true

deployment:
  # -- Deployment strategy type <https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies>
  updateStrategy:
    type: Recreate

spark:
  cluster:
    # -- ⚠️ Experimental: enable clustered mode for the Spark deployment. The Pathling server acts as the driver.
    enabled: false
    # -- the Spark master URL
    masterUrl: "k8s://https://kubernetes.default.svc"
    executor:
      # -- number of executor instances
      instances: 1
      # -- Amount of memory to use per executor process, in the same format as JVM memory strings with a size unit suffix ("k", "m", "g" or "t") (e.g. 512m, 2g).
      memory: ""
      request:
        # -- Specify the cpu request for each executor pod. Values conform to the Kubernetes convention.
        # Example values include 0.1, 500m, 1.5, 5, etc., with the definition of cpu units documented in CPU units.
        # This is distinct from spark.executor.cores: it is only used and takes precedence over spark.executor.cores
        # for specifying the executor pod cpu request if set. Task parallelism, e.g., number of tasks an executor
        # can run concurrently is not affected by this.
        cores: ""
        # -- executor pod container memory requests
        memory: ""
      limit:
        # -- Specify a hard cpu limit for each executor pod launched for the Spark Application.
        cores: ""
        # -- executor pod container memory limits
        memory: ""
      # -- executor pod template. Stored as YAML and mounted as a file specified in `spark.kubernetes.executor.podTemplateFile`.
      podTemplate: {}

# @ignored
curl: # +doc-gen:ignore
  image:
    registry: docker.io
    repository: curlimages/curl
    tag: 8.6.0@sha256:c3b8bee303c6c6beed656cfc921218c529d65aa61114eb9e27c62047a1271b9b

# -- container security context applied to init containers and the Helm test pods
# @ignored
restrictedContainerSecurityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  privileged: false
  capabilities:
    drop:
      - ALL
  runAsNonRoot: true
  runAsUser: 65534
  runAsGroup: 65534
  seccompProfile:
    type: RuntimeDefault

warehouse:
  # -- base URL at which Pathling will look for data files (`pathling.storage.warehouseUrl`).
  url: s3://pathling-warehouse
  s3:
    # -- S3 endpoint (`fs.s3a.endpoint`)
    endpoint: ""
    credentials:
      # -- access key for S3 (`fs.s3a.access.key`)
      accessKey: ""
      # -- secret key for S3 (`fs.s3a.secret.key`)
      secretKey: ""
      existingSecret:
        # -- name of an existing secret containing the access- and secret-key.
        name: ""
        # -- name of the key inside the secret that refers to the access key
        accessKeyKey: "s3-access-key"
        # -- name of the key inside the secret that refers to the secret key
        secretKeyKey: "s3-secret-key"
  file:
    persistence:
      # -- Enable file-based data persistence using PVC
      enabled: false
      # -- PVC storage class
      storageClass: ""
      # -- PVC Access Mode for data volume
      accessModes:
        - ReadWriteOnce
      # -- PVC Storage Request for data volume
      size: 8Gi
      # -- annotations for the PVC
      annotations: {}

minio:
  # -- set to `true` to enable the included minio sub-chart and auto-configure
  # the server to use it for storage
  enabled: true

  # -- create a bucket used for the pathling server warehouse by default.
  # See `warehouse.url`.
  defaultBuckets: "pathling-warehouse"

  # @ignored
  auth:
    existingSecret: ""

  # @ignored
  service:
    ports:
      api: 9000

  # @ignored
  containerSecurityContext:
    enabled: true
    allowPrivilegeEscalation: false
    runAsUser: 1001
    runAsNonRoot: true
    capabilities:
      drop:
        - ALL
    seccompProfile:
      type: RuntimeDefault

tests:
  # -- configure the test pods resource requests and limits
  resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi
